{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e7f383",
   "metadata": {},
   "source": [
    "# 3.b Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34ee843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import nltk\n",
    "from nltk import NaiveBayesClassifier, FreqDist\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cc441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c4c875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f931a1e",
   "metadata": {},
   "source": [
    "## Descriptive statistics of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fde9fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_of_words(text):\n",
    "    words=text.split()\n",
    "    word_count=len(words)\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef3bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc=df['review'].apply(no_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04d41894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean       231.156940\n",
       "std        171.343997\n",
       "min          4.000000\n",
       "25%        126.000000\n",
       "50%        173.000000\n",
       "75%        280.000000\n",
       "max       2470.000000\n",
       "Name: review, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b43216",
   "metadata": {},
   "source": [
    "## Synthetic Data Generating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c397d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract n-gram features from a document\n",
    "def document_features(document, ngram_features):\n",
    "    document_ngrams = list(nltk.ngrams(document, 2))\n",
    "    features = {}\n",
    "    for ngram in ngram_features:\n",
    "        features['contains({})'.format(ngram)] = (ngram in document_ngrams)\n",
    "    return features\n",
    "\n",
    "# Train a Naive Bayes classifier with n-gram features\n",
    "def train_naive_bayes_classifier(df, custom_vocab, n):\n",
    "    # Shuffle the DataFrame\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Select a subset of the DataFrame for demonstration purposes\n",
    "    df_subset = df.head(3000)\n",
    "\n",
    "    # Tokenize the reviews into words\n",
    "    all_words = [word.lower() for review in df_subset['review'] for word in word_tokenize(review)]\n",
    "\n",
    "    # Filter the words using the custom vocabulary\n",
    "    filtered_words = [word for word in all_words if word in custom_vocab]\n",
    "\n",
    "    # Create n-grams from the filtered words\n",
    "    ngrams = list(nltk.ngrams(filtered_words, n))\n",
    "\n",
    "    # Select the most frequent n-grams as features\n",
    "    ngram_features = [ngram for ngram, _ in FreqDist(ngrams).most_common(3000)]\n",
    "\n",
    "    # Create feature sets for training\n",
    "    featuresets = [(document_features(word_tokenize(review), ngram_features), sentiment)\n",
    "                   for review, sentiment in zip(df_subset['review'], df_subset['sentiment'])]\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    train_set, test_set = featuresets[:1500], featuresets[1500:]\n",
    "\n",
    "    # Train the Naive Bayes classifier\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    # Generate 10K movie reviews using the trained classifier\n",
    "    generated_reviews = []\n",
    "    sentiments = []\n",
    "    for _ in range(10000):\n",
    "        generated_review, sentiment = generate_movie_review(classifier, ngram_features)\n",
    "        generated_reviews.append(generated_review)\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "    # Create a DataFrame for the generated reviews and sentiments\n",
    "    result_df = pd.DataFrame({'Review': generated_reviews, 'Sentiment': sentiments})\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    result_df.to_csv(\"synthetic_reviews.csv\", index=False)\n",
    "    \n",
    "    return result_df, classifier, ngram_features\n",
    "\n",
    "# Function to generate a movie review using the trained classifier\n",
    "def generate_movie_review(classifier, ngram_features, length=50):\n",
    "    words = []\n",
    "    for _ in range(length):\n",
    "        # Use n-grams to generate the next word\n",
    "        ngram = random.choice(ngram_features)\n",
    "        words.extend(ngram)\n",
    "\n",
    "    # Classify the document using the Naive Bayes classifier\n",
    "    document = document_features(words, ngram_features)\n",
    "    sentiment = classifier.classify(document)\n",
    "\n",
    "    # Return the generated review and sentiment\n",
    "    generated_review = \" \".join(words)\n",
    "    return generated_review, sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93437846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Review Sentiment\n",
      "0     about his minutes and is just which the was it...  negative\n",
      "1     he can while it what she plenty of much to dea...  positive\n",
      "2     and get we have on their and again maybe it kn...  positive\n",
      "3     has no we do the idea the point to anyone it w...  negative\n",
      "4     best friend could not the dialogue why do amon...  negative\n",
      "...                                                 ...       ...\n",
      "9995  funny and the island the screen of mine happen...  positive\n",
      "9996  probably the is not is he dull and the women t...  negative\n",
      "9997  the years movie br but all it still know how i...  negative\n",
      "9998  movie ! his character him to for all it good w...  negative\n",
      "9999  what was with some supposed to so i the air wo...  positive\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load the IMDb dataset from the CSV file\n",
    "    df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n",
    "    # Read the custom vocabulary from the file\n",
    "    with open(\"imdb.vocab\", 'r', encoding='utf-8') as f:\n",
    "        custom_vocab = set(f.read().splitlines())\n",
    "\n",
    "    n = 2\n",
    "\n",
    "    # Generate a DataFrame for the generated reviews and sentiments\n",
    "    result_df, _, _ = train_naive_bayes_classifier(df, custom_vocab, n)\n",
    "\n",
    "    print(result_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56cc34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
